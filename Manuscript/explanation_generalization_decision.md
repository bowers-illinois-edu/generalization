---
title: "Explanation, Generalization, Decision: The Role of Cumulation in Policy
Design and Decision and the Role of PAPs and Research Integrity Practices there
in. Also Theory and Explanation."
author:
 - Jake Bowers^[<jwbowers@illinois.edu>]
 - James Kuklinski
header-includes: |
  \usepackage{fancyhdr}
  \fancypagestyle{myfancy}{%
    \fancyfoot[C]{}
    \fancyfoot[R]{PS 522 Spring 2021 --- \today --- \thepage}}
  \pagestyle{myfancy}
secnumdepth: 2
geometry: margin=1in
link-citations: true
numbersections: true
colorlinks: true
bibliography: ../../Research-Group-Bibliography/big.bib
biblatex: true
---

<!-- for APSA: Taking the example of attempts to encourage vaccination across
institutions and the example of a loosely coordinated study of early childhood
language learning (the Providence Talks Replication Study), we offer some
reflections on how the scientific workflow might need to change in order for
future collections of studies to be most policy relevant while also most
effectively and quickly advancing scientific explanation. For example, we show
that transparency and replicability principles arising to serve the sciences are
not directly political enough for use in policy and we advocate tighter
coordination between ethnographic teams of human centered designers, social
scientists, and data scientists. -->

# Introduction, Motivation, Overview

**The public policy problem:** Young children who grow up in low socioeconomic
status households score lower on reading related assessments, on average, than
young children growing up in higher SES households. This difference can make it
harder, in principle, for a society to provide an equal opportunity to both
kinds of children: they may attend the same school, but one group arrives behind
the other group in regards reading and language. In this case, equal schools
alone cannot provide equal opportunity.

**Theories of language development:**
Motivated by such persistent correlations and concerns about equality and
justice, researchers suggest several mechanisms by which low SES children arrive
in kindergarten less able to read than higher SES children by looking at
pre-kindergarten differences between high and low SES children. Such children
differ, for example, in their nutrition, the extent to which they may be exposed
to neighborhood or domestic violence, and also the number of words spoken to
them. Scholars have proposed different socio-neurological mechanisms linking
these and other differences to the end point of lower reading scores among the
poor than among the better off. For example, hearing words spoken to you may
increase your hearing vocabulary which in turn can make it easier to map meaning
onto words on the page.

**A public policy proposal:** A team of researchers has been pursuing the idea that
by improving the home language environment --- words spoken to a child, books
read to a child, two-way conversations with a child --- the "word gap" that maps
onto the SES gap can be diminished or erased --- and that thus, the early
elementary school academic achievement gap can be diminished or erased.

**A second order theory of behavior change:** To change children's vocabularies
and pre-kindergarten language development these researchers realized that they
have to change the behavior of adults, and especially parents and teachers of
toddlers in day-care facilities. So, they had a second order problem --- how to
change how parents and other adults use language around a toddler. Behavior
change is hard and much studied. The mechanism that these folks decided to focus
on involved feedback --- just as weight-loss behavior can be reinforced by using
a scale, they proposed to measure words spoken to children and two-way
conversations with children in the home (and childcare classrooms) and then to
reflect back to the parents and caretakers the measurements. A non-profit
corporation called LENA developed a vest that toddlers could wear which would
measure words spoken to them and words spoken with them without recording the
content of the conversations --- so that families would be willing to have their
toddlers wear these vests over multiple hours in their homes. LENA also
developed curricula --- slides, day by day talking points and activities --- so
that people could help parents interpret and use the data on their children. The
proposal was that cities should buy LENA devices and also buy LENA's curriculum
(books, etc..) and use them with people who could visit families and discuss the
interpret the data. The idea was to give each family a 10 week course of weekly
visits and coaching of this kind --- including bringing children's books to the
home and discussions of how to read with your child, topics of the week (like
"This week point out types of vehicles: car, truck, bike."), etc.. Thus,
parental behavior would change --- they would speak more to and with their
toddlers. Thus, toddler language developement would equalize between low and
higher income families. And thus, those children would arrive at kindergarten
better able to take advantage of the academic opportunities offered by the
schools. This was (and is) the hope and expectations. Hope based on values of
equality and social justice but also on large literatures on language
development, on behavior change and feedback, and on literatures that have
developed on precisely this topic (citations counts etc...)

**Preliminary aparent success:** A team of academics and early childhood
learning expertes rolled out this program in Providence, RI in 20XX (the
"Providence Talks" program). The (report)[] used an observational study design
and regression analysis to report success: that report showed families who
recorded their home language environments and who received visits from coaches
using the LENA curriculum improving their language home environment more than
families who had neither coaching nor word-recording.

In response, the Bloomberg Philanthropy decided to fund a
replication study involving RCTs in five other US cities: Detroit, Hartford,
Louisville, Birmingham, Virgina Beach. The Policy Lab at Brown University would
coordinate the studies. This paper is not the story of that project: it stopped
in the middle of COVID as it became more and more difficult to send coaches
into the homes of people with small children (let alone implement the other
features of the program --- including play groups, and coaching of day care
providers). But this paper engages with some of the questions that arose that
were not so easy to answer using what we knew from the scholarly literature.

For example, we had to ask why would policy decisionmakers or the scientific
community want to replicate this study?  Wouldn't it be enough to read the
reports written by the non-profit corporation who developed and sell the
technology? Or wouldn't it be enough to read the observational study based in
and around Providence, RI?

What did they hope to gain? What should anyone hope to gain?  How much
replication? For what purpose?

We claim that they really want to improve their confidence in explanations, and
perhaps to fine tune them. And that they are aware that "causality operates in
context".

We also point out that a desire for replication here is a desire for increased
believability of findings. Certain findings do not seem to help us increase (or
decrease) the beliefs that we may previously hold.


There are at least two kinds of policy actors here (here focusing on people with
direct responsibility for early childhood public programs for low income
children, for example, not focusing on national or state level policy
activitists and lobbyists or pundits etc..):

So, why would someone in charge of early childhood programs in Birmingham want
to replicate the Providence study using an RCT instead of an observational study
in Birmingham?

Why would someone in city other than those chosen for the replication, say,
Urbana, find the results of 1 city observational study plus a 5 city loosely
coordinatd RCT better for the purposes of informing their decisions about
Urbana, then just the single study?

While we can explain why someone might prefer an RCT over an observational study
(citations) easily: the families in the Providence Study who were not offered
the word-recording and coaching differed from the families who did receive
coaching and recording in many ways --- ways that the researchers measured and
attempted to adjust away using regression models, and ways that the researchers
did not measure and so could not adjust away. We are left wondering both (1)
whether the families who participated in Providence were particularly likely to
benefit from the bundle of the intervention (Coaching/Recording/Feedback)
compared to those living just outside Providence who did not get it, (2) whether
language development in the families who participated would have been faster and
better over the months of the study compared to the other non-participating
families because those focal, or interevention-families, cared more about
toddler language development in the first place --- thus they signed up for the
study. In an RCT we could have set aside such worries. We would have been able
to report on what we had learned with more confidence --- that the treatment
bundle caused differences in language  development (or at least, the treatment
bundle and anything that came along with it).

So, we can see why those responsible for low-income early childhood education in
other city, including Providence, would prefer a replication that is an RCT. We
can also see how the RCT would raise new questions for them (see Cartwright and
hardie): if people could choose to participate or not, would we see that the
program was less effective? (Recall that decision makers must evaluate this
program in the context of others --- each one costs money and time. Recording
words counts without storing recordings of words, for example, requires devices
and software and IT support. Coaching requires coaches and training and
materials.) That is, would familie who want to focus on their home language
environment sign up, but these families would be the ones who would do other
encirchment activities even in the absence of the program? The RCT on its own
does not tell us about its effect on the kinds of families who would relish it
versus avoid it. Nor does it help decision makers figure out how to bring it
into the homes of people who would not ordinarily want to sign up for it:
families which do not think that language learning in their home for their
toddlers requires this kind of effort, or who are focusing on other aspects of
parenting and life in general.

Further, imagine that the debate in the community of those working to improve
early childhood language learning among low income toddlers is between spending
money on recording words and sending coaches to homes versus just giving cash to
families. The later idea arises from the idea of guaranteed income,
unconditional cash tranfers in development economics, etc... Would an RCT in
Providence inform this debate?

But at least one RCT tells us something clear; something that can be a base for other
discussion.

Imagine we had an RCT from Providence. Why would folks in Birmingham want to
replicate it in Birmingham? Why would folks in Urbana be grateful for a
replication in Birmingham (or would they?)

The desire to replicate in Birmingham has to do with three factors: (1)
differences in treatment and (2) differences in the way context might change the
treatment effect  and (3) how (and when) outcomes are measured.

Imagine that services for low income families with toddlers in Providence was
provided from a social services agency that used social workers and in
Birmingham it would be provided via home-visiting nurses. Would coaching and
word-count data interpretation from a nurse who was visiting to check the health
of the child differ from the way a social worker might provide those services?
In fact, as we planned this experiment we learned that each of the five cities
has (1) pre-existing processes and agencies to provide services to low income
families, low income toddlers and (2) that they all differ from one another.
These places each had a story about why their methods (say, bidding out
contracts to multiple neighborhood based small organizations, relying on nurses
who follow women from before birth to a couple of years after birth, etc.) imply
a very different approach to implementing the word-counting and coaching, and
that thus that their city would expect a different result than any other city.

The decision makers in each city not only worried that their very structures for
implementing the new policy intervention differed, but that the context of their
cities differed: poverty in one city might be concentrated among relatively
recent Spanish speaking immigrants, while it might be concentrated in
historically marginalized neighborhoods segregated by Black/White race in the US
South. Of course the word-counter technology adapted to Spanish word use. But,
simple comparisons of numbers of words, for example, might not be meaningful
given differences in language. Further, the families relationships are socially
and culturally constructed differently, jobs outside the home for mothers
differed in participation by women, and the relationships between the city
governments and public services and these groups differed in terms of
cooperation and suspicion.

Third, different cities measure language ability among their school children at
different ages --- not every place measures in kindergarten. Among those who
measure at the same age, we discovered that different school districts and
state-level education agencies mandate different tests. The experts in childhood
language in the room even disagreed on which test measured concepts like
"kindergarten language ability" best (among native English speakers).

Yet, all agreed to the replication. Why?

One reason is that they were given money for their own individual city-based and
individual city-designed programs on the condition that they do an RCT in a
coordinated fashion.

A second reason was that each city feared that they could not serve enough
families in order to detect a treatment effect from noise. It is costly to visit
families in their homes. If a city only had 10 nurses, those nurses could only
visit maybe 100 families over the course of 10 weeks. Would 50 families in the
treatment group and 50 in the control group allow researchers to distinguish a
treatmetn effect from zero, to announce "statistically significant" for that
given city? One idea was that if the experiment could be analyzed as if it were
done in 5 blocks --- with say, a total of 250 families in treatment and 250 in
control --- then the statistical results would be stronger. That is, then, at
the level of the nation or for Bloomberg, the group of cities would be able to
contribute to an overall assessment of the benefits of this treatment.
 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.

 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.

 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.














# References
