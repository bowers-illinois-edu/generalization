---
title: "Explanation, Generalization, Decision: The Role of Cumulation in Policy
Design and Decision and the Role of PAPs and Research Integrity Practices there
in. Also Theory and Explanation."
author:
 - Jake Bowers^[<jwbowers@illinois.edu>]
 - James Kuklinski
header-includes: |
  \usepackage{fancyhdr}
  \fancypagestyle{myfancy}{%
    \fancyfoot[C]{}
    \fancyfoot[R]{Version of --- \today --- \thepage}}
  \pagestyle{myfancy}
secnumdepth: 2
geometry: margin=1in
link-citations: true
numbersections: true
colorlinks: true
bibliography: ../../Research-Group-Bibliography/big.bib
biblatex: true
---

<!-- for APSA: Taking the example of attempts to encourage vaccination across
institutions and the example of a loosely coordinated study of early childhood
language learning (the Providence Talks Replication Study), we offer some
reflections on how the scientific workflow might need to change in order for
future collections of studies to be most policy relevant while also most
effectively and quickly advancing scientific explanation. For example, we show
that transparency and replicability principles arising to serve the sciences are
not directly political enough for use in policy and we advocate tighter
coordination between ethnographic teams of human centered designers, social
scientists, and data scientists. -->


Key points:
 - Any one or several studies helps policy makers make decisions to the extent
   that they fill in the theory of change held implicitly or explicitly by the
   decision maker. Imagien a theory of change as a DAG. If a study informs me
   something new about a path over which I have control / could make a change /
   am considering a change, then I might use that study.

 - For an academic: "Does this study generalize?" means "I am having trouble
   fitting the results of this study into my DAG." and "I would like to think
   that I could use this finding to reason about what I might expect in another
   context should I be asked to advise a decision maker." Or "I would like to
   use this finding to add confidence in parts of the DAG that the scientific
   community is creating."

 - For a decision maker (or group of them, like a city council): Care less about
   generalizing per se, and more about what a given study or set of them have to
   say about possibilites in a given place.


Imagine that that only one Providence Talks replication study was able to be
completed and it was the one in Birminham, Alabama. Imagine it showed that
families receiving the coaching plus feedback about the device ended
up speaking more with their child at the end, and had more conversations with
their child. Imagine that it also showed that those children had higher scores
in kindergarten readiness than children in the control group. What might this
mean for you if you were considering spending effort on policies focused on low
income children? (Knowing that you might be consumed with policies to fix roads,
etc.. and that low income children kindergarten readiness while important of
course might not always be the primary policy  priority.)

What about if all 5 cities had been able to complete the project and that more
or less the same results were seen across them all? Would that change anything?

What kind of study not in your own city would be most useful?

Issues: We may not all share a DAG. Even if we do share a DAG certain variables
are fixed (too difficult to change) and others are not --- and this varies
across places. Arrows from fixed variables don't help me much as a policy
maker.

So: 
 - COuld be worth asking for DAGs from policy decision makers before you do one
   or even coordinated studies. Studies that randomize something that no
   decision maker would change are not helpful to that person, for example. 
 - Also could be that evidence (say, RCTs) can inform policy even if those RCTs
   do not evaluate a whole policy in an ITT form. An RCT that provides focused
   information about one arrow might be more useful than an RCT that provides an
   ITT style result, for example.
 - Role of context: similar to the fixed variables. Often these are implicit.
   Evaluate effect of the kind of policy intervention that is meaningful right
   now --- postcards, say. But this assumes mailboxes and a mailing service and
   literacy. Importance of trying to figure this out --- pre-mortems, dark
   logic, participatory DAG creation, mobilizing creativity.
 - Another implication: scientific community kind of provides the DAGs. What if
   we have a DAG that says "Stricking Match --> Friction --> Flame" makes sense.
   Are we wrong if someone tries this on the Moon and discovered that it does
   work? In fact we only have a partial story. And the failure to get flame on
   the moon from striking a match is useful --- it reveals that we need consider
   what else we should add to the DAG (and why, what is it about Friction, etc..
   that causes flame?)


For the policy maker the question is not whether one can predict the effect of
doing the intervention as done in City B in her own City A. This is pretty rare.
Mostly the way that the intevention would occur in City A will differ. Learning
about a similar intervention and similar context in City B should help. And
perhaps a City C that is like CIty B might also help. And a City D that is
?different from either B or C? might also help?  But this makes this task a bit
different from the task focused on by, say, Pearl and Bareimboim (2014, 2016).
That task might be useful and may well add a lot --- but I suspect it adds more
because of the DAG than because of the prediction.

(from a persentation by Cinelli and Bareimboim)

>“‘External validity’ asks the question of generalizability: To what populations, settings, treatment variables, and measurement variables can this effect be generalized?”
• Shadish, Cook and Campbell (2002) 

> “Extrapolation across studies requires ‘some understanding of the reasons for the differences.’”
• Cox (1958)
> “An experiment is said to have “external validity” if the distribution of outcomes realized by a treatment group is the same as the distribution of outcome that would be realized in an actual program.”
Manski (2007)























What does a policy expert making decisions for the good of the people in city A
tomorrow learn from a study done in city B yesterday or last year or ten years
ago? What should such a person learn from other studies in other cities in
other times? What research practices might help this person learn better / use
the public / published information more effectively or less effectively?

We engage with these questions in an effort to help (1) help policy oriented
research teams adapt research integrity practices from the social sciences to
their context and (2) help those who are considering coordinated experiments or
studies plan them so as to most effectively enhance evidence-based  policy decision making.

Overall points:
 - Policy decisions should help a fixed set of people in a fixed place over a
   more or less fixed time (perhaps time is most flexible). If I am in charge of
   helping families with young children enhance the language development of
   those toddlers in a given place, that is my job, my focus. I am not hoping to
   improve the lives of people in other places or other times except very
   secondarily as people learn about what I do. And, in fact, teaching others
   about what I do is secondary or tertiary. If by chance people outside my
   place learn, then fine. But it is no where near the most important thing.
 - This means that learning that the estimated causal effect of an intervention
   is 100 words plus or minus 20 words (for example) in one other city can only
   be used in terms of **sign** not magnitude. What matters in fact is that it
   would be very surprising to see 100 if the null were true or that we "can
   detect an effect".  (More decision makers should pay more attention to
   magnitude -- after all, a detectable effect of 10 words may not be worth the
   expense of the program. But these conversations --- "how large of an effect
   would be necessary to justify the expense of the program"  have turned out to
   be very difficult in many areas --- it is hard to monetize, say, academic
   inequality or equality. We set this aside for now but may be an important
   task to tackle in the future --- how to help people reason about whether a
   study would be worthwhile given different costs of programs and anticipated
   benefits.) 
 - This also means that "statistical significance" seems to matter --- people do
   not have well development judgements about continuous p-values. Or, say,
   "posterior probability that the effect is greater than 0".
 - So, savvy decision makers are not looking for forecasts in most cases ---
   they understand that (1) the ways in which their city will provide the
   intervention differs from other cities (in statistical terms, the nature of
   the treatment will differ), the measurement of the outcome will differ, the
   ways in which the context of the city facilitates or hinders the causal
   mechanism linking intervention to outcome differs in their city from other
   cities. (This is not so different from family decision makers by the way. Of
   course we know that, on average 5 servings of fruit or vegetables per day is
   associated with better health outcomes for kids. Yet, we don't imagine that
   this is a forecast for a given family. It is better than nothing but each
   family knows it is not the average family and so must make its own decisions
   in regards fruit and vegetable servings.)

So, one other study provides information to the extent that it comes from
similar places (i.e. similar covariate distributions) and perhaps a sense that
the intervention to covariate interactions are similar, and intervention
provision is similar, and outcome measurement and scale is similar.

What about effects found in 5 cities that are not particularly similar to ones
own city? If those 5 were all the same basically, then it would be just like one
big study of a dissimilar city: bigger study is better for sure.  If those 5
differed from the focal city but also from each other, is this better
information? (I think so.) Would "statistically significant" in all of those
cities warrant action in the focal city? Maybe. Unless there are some key
moderators that differ: maybe the causal mechanism only functions well under
certain circumstances --- say, if there is no civil war in the city; or the
coaches are native speakers of the home language of the family (for example, a
growing number of families in the USA are categorized as Spanish speakers as
coming from Guatemala but are in fact speakers of Mayan dialects in the home.) 

What about credibility? Why should a decision maker believe that the results are
what they are? Policy decisions are often politicized or at least occur in the
context of alternatives: should we spend the money on coaching and LENA devices
or just give cash to families or build more libraries near these people? If the
results appear to have come from a research team with a particular political
point of view, what does that mean? 

Should a decision maker in City A pay to support a study in Cities B,C, and D?
even if those cities differ from City in key ways? 

What if the decision maker instead pays for a study in City A itself. Does this
result provide clear avenues for action? It might. What would studies in other
cities add here? (I'd say they would add some information about how the
intervention might change if the context changes --- and since the context will
change, a savvy decision maker would want to implement a policy knowning this,
perhaps planning in advance for such changes.) For example, flood prevention in
cities that have not yet had serious floods --- engineers in those cities look
to other cities that have had recent floods to learn. Houston is not Chicago,
but the flooding of Houston from the Hurricane Blah can teach enginners in
Chicago about their storm sewers.

Notice also: decisions tend to emerge from committees with lots of influence
from stakeholders as well as a few influential voices. So, there tends not to be
a single decision maker.

I think that first a city council (say) is adding up advantages and
disadvantages of any given new idea --- say, spending money to deploy coaches to
provide feedback to parents about words spoken in their home as recorded by some
privacy protecting technology.  Some of the advantages and disadvantages are
about how such an intervention might be received/interpreted by those who do not
directly benefit but who are constituents: why not spend the money on splash
parks, we know that exercise is good and more kids can access this, not just the
few poorest children? Why not just give half of the money allocated to coaches
and devices to the families directly and the other half to splash parks --- a
compromise, families can even be told that they can spend their money on LENA
devices and coaching online.

What can studies done elsewhere add to this discussion? Imagine the debate is
between three mechanisms to improve the lives of low income toddlers: exercise
and the outdoors (could be over 1 year if we want to staff the splash parks, or
spend to advertise them, etc..), feedback about home language over about 1 year
period, and moderately increased income over a 1 year period,










What if a decision maker group in City A could draw a DAG. And a group of
researchers could claim to have learned about a causal effect 












# Introduction, Motivation, Overview

**The public policy problem:** Young children who grow up in low socioeconomic
status households score lower on reading related assessments, on average, than
young children growing up in higher SES households. This difference can make it
harder, in principle, for a society to provide an equal opportunity to both
kinds of children: they may attend the same school, but one group arrives behind
the other group in regards reading and language. In this case, equal schools
alone cannot provide equal opportunity.

**Theories of language development:**
Motivated by such persistent correlations and concerns about equality and
justice, researchers suggest several mechanisms by which low SES children arrive
in kindergarten less able to read than higher SES children by looking at
pre-kindergarten differences between high and low SES children. Such children
differ, for example, in their nutrition, the extent to which they may be exposed
to neighborhood or domestic violence, and also the number of words spoken to
them. Scholars have proposed different socio-neurological mechanisms linking
these and other differences to the end point of lower reading scores among the
poor than among the better off. For example, hearing words spoken to you may
increase your hearing vocabulary which in turn can make it easier to map meaning
onto words on the page.

**A public policy proposal:** A team of researchers has been pursuing the idea that
by improving the home language environment --- words spoken to a child, books
read to a child, two-way conversations with a child --- the "word gap" that maps
onto the SES gap can be diminished or erased --- and that thus, the early
elementary school academic achievement gap can be diminished or erased.

**A second order theory of behavior change:** To change children's vocabularies
and pre-kindergarten language development these researchers realized that they
have to change the behavior of adults, and especially parents and teachers of
toddlers in day-care facilities. So, they had a second order problem --- how to
change how parents and other adults use language around a toddler. Behavior
change is hard and much studied. The mechanism that these folks decided to focus
on involved feedback --- just as weight-loss behavior can be reinforced by using
a scale, they proposed to measure words spoken to children and two-way
conversations with children in the home (and childcare classrooms) and then to
reflect back to the parents and caretakers the measurements. A non-profit
corporation called LENA developed a vest that toddlers could wear which would
measure words spoken to them and words spoken with them without recording the
content of the conversations --- so that families would be willing to have their
toddlers wear these vests over multiple hours in their homes. LENA also
developed curricula --- slides, day by day talking points and activities --- so
that people could help parents interpret and use the data on their children. The
proposal was that cities should buy LENA devices and also buy LENA's curriculum
(books, etc..) and use them with people who could visit families and discuss the
interpret the data. The idea was to give each family a 10 week course of weekly
visits and coaching of this kind --- including bringing children's books to the
home and discussions of how to read with your child, topics of the week (like
"This week point out types of vehicles: car, truck, bike."), etc.. Thus,
parental behavior would change --- they would speak more to and with their
toddlers. Thus, toddler language developement would equalize between low and
higher income families. And thus, those children would arrive at kindergarten
better able to take advantage of the academic opportunities offered by the
schools. This was (and is) the hope and expectations. Hope based on values of
equality and social justice but also on large literatures on language
development, on behavior change and feedback, and on literatures that have
developed on precisely this topic (citations counts etc...)

**Preliminary aparent success:** A team of academics and early childhood
learning expertes rolled out this program in Providence, RI in 20XX (the
"Providence Talks" program). The (report)[] used an observational study design
and regression analysis to report success: that report showed families who
recorded their home language environments and who received visits from coaches
using the LENA curriculum improving their language home environment more than
families who had neither coaching nor word-recording.

In response, the Bloomberg Philanthropy decided to fund a
replication study involving RCTs in five other US cities: Detroit, Hartford,
Louisville, Birmingham, Virgina Beach. The Policy Lab at Brown University would
coordinate the studies. This paper is not the story of that project: it stopped
in the middle of COVID as it became more and more difficult to send coaches
into the homes of people with small children (let alone implement the other
features of the program --- including play groups, and coaching of day care
providers). But this paper engages with some of the questions that arose that
were not so easy to answer using what we knew from the scholarly literature.

For example, we had to ask why would policy decisionmakers or the scientific
community want to replicate this study?  Wouldn't it be enough to read the
reports written by the non-profit corporation who developed and sell the
technology? Or wouldn't it be enough to read the observational study based in
and around Providence, RI?

What did they hope to gain? What should anyone hope to gain?  How much
replication? For what purpose?

We claim that they really want to improve their confidence in explanations, and
perhaps to fine tune them. And that they are aware that "causality operates in
context".

We also point out that a desire for replication here is a desire for increased
believability of findings. Certain findings do not seem to help us increase (or
decrease) the beliefs that we may previously hold.


There are at least two kinds of policy actors here (here focusing on people with
direct responsibility for early childhood public programs for low income
children, for example, not focusing on national or state level policy
activitists and lobbyists or pundits etc..):

So, why would someone in charge of early childhood programs in Birmingham want
to replicate the Providence study using an RCT instead of an observational study
in Birmingham?

Why would someone in city other than those chosen for the replication, say,
Urbana, find the results of 1 city observational study plus a 5 city loosely
coordinatd RCT better for the purposes of informing their decisions about
Urbana, then just the single study?

While we can explain why someone might prefer an RCT over an observational study
(citations) easily: the families in the Providence Study who were not offered
the word-recording and coaching differed from the families who did receive
coaching and recording in many ways --- ways that the researchers measured and
attempted to adjust away using regression models, and ways that the researchers
did not measure and so could not adjust away. We are left wondering both (1)
whether the families who participated in Providence were particularly likely to
benefit from the bundle of the intervention (Coaching/Recording/Feedback)
compared to those living just outside Providence who did not get it, (2) whether
language development in the families who participated would have been faster and
better over the months of the study compared to the other non-participating
families because those focal, or interevention-families, cared more about
toddler language development in the first place --- thus they signed up for the
study. In an RCT we could have set aside such worries. We would have been able
to report on what we had learned with more confidence --- that the treatment
bundle caused differences in language  development (or at least, the treatment
bundle and anything that came along with it).

So, we can see why those responsible for low-income early childhood education in
other city, including Providence, would prefer a replication that is an RCT. We
can also see how the RCT would raise new questions for them (see Cartwright and
hardie): if people could choose to participate or not, would we see that the
program was less effective? (Recall that decision makers must evaluate this
program in the context of others --- each one costs money and time. Recording
words counts without storing recordings of words, for example, requires devices
and software and IT support. Coaching requires coaches and training and
materials.) That is, would familie who want to focus on their home language
environment sign up, but these families would be the ones who would do other
encirchment activities even in the absence of the program? The RCT on its own
does not tell us about its effect on the kinds of families who would relish it
versus avoid it. Nor does it help decision makers figure out how to bring it
into the homes of people who would not ordinarily want to sign up for it:
families which do not think that language learning in their home for their
toddlers requires this kind of effort, or who are focusing on other aspects of
parenting and life in general.

Further, imagine that the debate in the community of those working to improve
early childhood language learning among low income toddlers is between spending
money on recording words and sending coaches to homes versus just giving cash to
families. The later idea arises from the idea of guaranteed income,
unconditional cash tranfers in development economics, etc... Would an RCT in
Providence inform this debate?

But at least one RCT tells us something clear; something that can be a base for other
discussion.

Imagine we had an RCT from Providence. Why would folks in Birmingham want to
replicate it in Birmingham? Why would folks in Urbana be grateful for a
replication in Birmingham (or would they?)

The desire to replicate in Birmingham has to do with three factors: (1)
differences in treatment and (2) differences in the way context might change the
treatment effect  and (3) how (and when) outcomes are measured.

Imagine that services for low income families with toddlers in Providence was
provided from a social services agency that used social workers and in
Birmingham it would be provided via home-visiting nurses. Would coaching and
word-count data interpretation from a nurse who was visiting to check the health
of the child differ from the way a social worker might provide those services?
In fact, as we planned this experiment we learned that each of the five cities
has (1) pre-existing processes and agencies to provide services to low income
families, low income toddlers and (2) that they all differ from one another.
These places each had a story about why their methods (say, bidding out
contracts to multiple neighborhood based small organizations, relying on nurses
who follow women from before birth to a couple of years after birth, etc.) imply
a very different approach to implementing the word-counting and coaching, and
that thus that their city would expect a different result than any other city.

The decision makers in each city not only worried that their very structures for
implementing the new policy intervention differed, but that the context of their
cities differed: poverty in one city might be concentrated among relatively
recent Spanish speaking immigrants, while it might be concentrated in
historically marginalized neighborhoods segregated by Black/White race in the US
South. Of course the word-counter technology adapted to Spanish word use. But,
simple comparisons of numbers of words, for example, might not be meaningful
given differences in language. Further, the families relationships are socially
and culturally constructed differently, jobs outside the home for mothers
differed in participation by women, and the relationships between the city
governments and public services and these groups differed in terms of
cooperation and suspicion.

Third, different cities measure language ability among their school children at
different ages --- not every place measures in kindergarten. Among those who
measure at the same age, we discovered that different school districts and
state-level education agencies mandate different tests. The experts in childhood
language in the room even disagreed on which test measured concepts like
"kindergarten language ability" best (among native English speakers).

Yet, all agreed to the replication. Why?

One reason is that they were given money for their own individual city-based and
individual city-designed programs on the condition that they do an RCT in a
coordinated fashion.

A second reason was that each city feared that they could not serve enough
families in order to detect a treatment effect from noise. It is costly to visit
families in their homes. If a city only had 10 nurses, those nurses could only
visit maybe 100 families over the course of 10 weeks. Would 50 families in the
treatment group and 50 in the control group allow researchers to distinguish a
treatmetn effect from zero, to announce "statistically significant" for that
given city? One idea was that if the experiment could be analyzed as if it were
done in 5 blocks --- with say, a total of 250 families in treatment and 250 in
control --- then the statistical results would be stronger. That is, then, at
the level of the nation or for Bloomberg, the group of cities would be able to
contribute to an overall assessment of the benefits of this treatment.
 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.

 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.

 Would 50 families in the treatment group and 50 in the control group allow
 researchers to distinguish a treatmetn effect from zero, to announce
 "statistically significant" for that given city? One idea was that if the
 experiment could be analyzed as if it were done in 5 blocks --- with say, a
 total of 250 families in treatment and 250 in control --- then the statistical
 results would be stronger. That is, then, at the level of the nation or for
 Bloomberg, the group of cities would be able to contribute to an overall
 assessment of the benefits of this treatment.














# References
